{"cells":[{"cell_type":"code","execution_count":131,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T19:32:09.138376Z","iopub.status.busy":"2021-12-20T19:32:09.138112Z","iopub.status.idle":"2021-12-20T19:32:09.150882Z","shell.execute_reply":"2021-12-20T19:32:09.149891Z","shell.execute_reply.started":"2021-12-20T19:32:09.138347Z"},"trusted":true},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd \n","import os\n","from glob import glob\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","import random\n","from random import sample\n","import sklearn.model_selection as skl\n","from kaggle_datasets import KaggleDatasets\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras_preprocessing.image.dataframe_iterator import DataFrameIterator\n","from tensorflow.keras.applications import EfficientNetB3\n","from keras.applications.vgg16 import VGG16\n","from tensorflow.keras.layers import InputLayer, GlobalAveragePooling2D, BatchNormalization, Dense, Dropout, Flatten, Conv2D, MaxPooling2D \n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.metrics import AUC\n","from tensorflow.keras.optimizers import RMSprop\n","import tensorflow_hub as tfhub\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n","\n","import pydicom\n","import cv2"]},{"cell_type":"markdown","metadata":{},"source":["## Replace the root directory BELOW with appropriate directory folder pointing to Brats2021 dataset ->\n","https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification"]},{"cell_type":"code","execution_count":132,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T19:32:09.153674Z","iopub.status.busy":"2021-12-20T19:32:09.153339Z","iopub.status.idle":"2021-12-20T19:32:09.169090Z","shell.execute_reply":"2021-12-20T19:32:09.168134Z","shell.execute_reply.started":"2021-12-20T19:32:09.153607Z"},"trusted":true},"outputs":[],"source":["#Replace the root directory below\n","root_dir = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/'\n","df = pd.read_csv(root_dir+'train_labels.csv')"]},{"cell_type":"code","execution_count":133,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T19:32:09.175343Z","iopub.status.busy":"2021-12-20T19:32:09.175130Z","iopub.status.idle":"2021-12-20T19:32:09.190932Z","shell.execute_reply":"2021-12-20T19:32:09.190106Z","shell.execute_reply.started":"2021-12-20T19:32:09.175313Z"},"trusted":true},"outputs":[],"source":["# Add the full paths for each id for different types of sequences to the csv \n","def full_ids(data):\n","    zeros = 5 - len(str(data))\n","    if zeros > 0:\n","        prefix = ''.join(['0' for i in range(zeros)])\n","    \n","    return prefix+str(data)\n","        \n","\n","df['BraTS21ID_full'] = df['BraTS21ID'].apply(full_ids)\n","\n","# Add all the paths to the df for easy access\n","df['flair'] = df['BraTS21ID_full'].apply(lambda file_id : root_dir+'train/'+file_id+'/FLAIR/')\n","df['t1w'] = df['BraTS21ID_full'].apply(lambda file_id : root_dir+'train/'+file_id+'/T1w/')\n","df['t1wce'] = df['BraTS21ID_full'].apply(lambda file_id : root_dir+'train/'+file_id+'/T1wCE/')\n","df['t2w'] = df['BraTS21ID_full'].apply(lambda file_id : root_dir+'train/'+file_id+'/T2w/')"]},{"cell_type":"code","execution_count":134,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T19:32:09.192499Z","iopub.status.busy":"2021-12-20T19:32:09.192306Z","iopub.status.idle":"2021-12-20T19:32:09.209143Z","shell.execute_reply":"2021-12-20T19:32:09.208238Z","shell.execute_reply.started":"2021-12-20T19:32:09.192475Z"},"trusted":true},"outputs":[],"source":["df_test = pd.read_csv(root_dir+'sample_submission.csv')\n","\n","df_test['BraTS21ID_full'] = df_test['BraTS21ID'].apply(full_ids)\n","\n","# Add all the paths to the df for easy access\n","df_test['flair'] = df_test['BraTS21ID_full'].apply(lambda file_id : root_dir+'test/'+file_id+'/FLAIR/')\n","df_test['t1w'] = df_test['BraTS21ID_full'].apply(lambda file_id : root_dir+'test/'+file_id+'/T1w/')\n","df_test['t1wce'] = df_test['BraTS21ID_full'].apply(lambda file_id : root_dir+'test/'+file_id+'/T1wCE/')\n","df_test['t2w'] = df_test['BraTS21ID_full'].apply(lambda file_id : root_dir+'test/'+file_id+'/T2w/')"]},{"cell_type":"markdown","metadata":{},"source":["# Load the dataset and split into training and testing dataframes"]},{"cell_type":"code","execution_count":135,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T19:32:09.211140Z","iopub.status.busy":"2021-12-20T19:32:09.210868Z","iopub.status.idle":"2021-12-20T19:32:09.235864Z","shell.execute_reply":"2021-12-20T19:32:09.234867Z","shell.execute_reply.started":"2021-12-20T19:32:09.211105Z"},"trusted":true},"outputs":[],"source":["def get_train_val_dataframe(mri_type):\n","    \n","    all_img_files = []\n","    all_img_labels = []\n","    all_img_patient_ids = []\n","    for row in df.iterrows():\n","        if row[1]['BraTS21ID_full'] == '00109' and mri_type == 'flair':\n","            continue\n","        if row[1]['BraTS21ID_full'] == '00123' and mri_type == 't1w':\n","            continue\n","        if row[1]['BraTS21ID_full'] == '00709' and mri_type == 'flair':\n","            continue\n","        img_dir = row[1][mri_type]\n","        img_files = os.listdir(img_dir)\n","        img_nums = sorted([int(ele.replace('Image-', '').replace('.dcm', '')) for ele in img_files])\n","        mid_point = int(len(img_nums)/2)\n","        start_point = mid_point - max(int(mid_point*0.1), 1)\n","        end_point = mid_point + max(int(mid_point*0.1), 1)\n","        img_names = [f'Image-{img_nums[i]}.dcm' for i in range(start_point, end_point+1)]\n","        img_paths = [img_dir+ele for ele in img_names]\n","        img_labels = [row[1]['MGMT_value']]*len(img_paths)\n","        img_patient_ids = [row[1]['BraTS21ID']]*len(img_paths)\n","        all_img_files.extend(img_paths)\n","        all_img_labels.extend(img_labels)\n","        all_img_patient_ids.extend(img_patient_ids)\n","\n","    train_val_df = pd.DataFrame({'patient_ids': all_img_patient_ids,\n","                  'labels': all_img_labels,\n","                  'file_paths': all_img_files})\n","\n","    train_val_df['labels'] = train_val_df['labels'].map({1: '1', 0: '0'})\n","     \n","    class_prop= 0.90\n","    \n","    classes_splits  = {}\n","    for i in range(2):\n","        train_val_label_class = train_val_df[train_val_df['labels']==f'{i}']\n","        train_val_list_ids =  list(train_val_label_class['patient_ids'].unique())\n","        train_threshold = math.ceil(class_prop*len(train_val_list_ids))\n","        train_ids = train_val_list_ids[:train_threshold]\n","        val_ids = train_val_list_ids[train_threshold:]\n","        classes_splits[f'train_{i}'] = train_val_label_class[train_val_label_class['patient_ids'].isin(train_ids)]\n","        classes_splits[f'val_{i}'] = val_df = train_val_label_class[train_val_label_class['patient_ids'].isin(val_ids)]\n","        \n","    train_df = pd.concat([classes_splits['train_0'], classes_splits['train_1']], axis=0)\n","    val_df = pd.concat([classes_splits['val_0'], classes_splits['val_1']], axis=0)\n","  \n","    return train_df, val_df\n","    \n","def get_test_dataframe(mri_type):\n","    \n","    all_test_img_files = []\n","    all_test_img_labels = []\n","    all_test_img_patient_ids = []\n","    for row in df_test.iterrows():\n","        img_dir = row[1][mri_type]\n","        img_files = os.listdir(img_dir)\n","        img_nums = sorted([int(ele.replace('Image-', '').replace('.dcm', '')) for ele in img_files])\n","        mid_point = int(len(img_nums)/2)\n","        start_point = mid_point - max(int(mid_point*0.1), 1)\n","        end_point = mid_point + max(int(mid_point*0.1), 1)\n","        img_names = [f'Image-{img_nums[i]}.dcm' for i in range(start_point, end_point+1)]\n","        img_paths = [img_dir+ele for ele in img_names]\n","        img_labels = [row[1]['MGMT_value']]*len(img_paths)\n","        img_patient_ids = [row[1]['BraTS21ID']]*len(img_paths)\n","        all_test_img_files.extend(img_paths)\n","        all_test_img_labels.extend(img_labels)\n","        all_test_img_patient_ids.extend(img_patient_ids)\n","\n","    test_df = pd.DataFrame({'patient_ids': all_test_img_patient_ids,\n","                  'labels': all_test_img_labels,\n","                  'file_paths': all_test_img_files})\n","    \n","    test_df['labels'] = ['1']*(len(test_df)-1) + ['0'] \n","    \n","    return test_df"]},{"cell_type":"markdown","metadata":{},"source":["##Create a DCM DataFrame Iterator"]},{"cell_type":"code","execution_count":136,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T19:32:09.238230Z","iopub.status.busy":"2021-12-20T19:32:09.237953Z","iopub.status.idle":"2021-12-20T19:32:09.252104Z","shell.execute_reply":"2021-12-20T19:32:09.251390Z","shell.execute_reply.started":"2021-12-20T19:32:09.238195Z"},"trusted":true},"outputs":[],"source":["class DCMDataFrameIterator(DataFrameIterator):\n","    def __init__(self, *arg, **kwargs):\n","        self.white_list_formats = ('dcm')\n","        super(DCMDataFrameIterator, self).__init__(*arg, **kwargs)\n","        self.dataframe = kwargs['dataframe']\n","        self.x = self.dataframe[kwargs['x_col']]\n","        self.y = self.dataframe[kwargs['y_col']]\n","        self.color_mode = kwargs['color_mode']\n","        self.target_size = kwargs['target_size']\n","\n","    def _get_batches_of_transformed_samples(self, indices_array):\n","        # get batch of images\n","        batch_x = np.array([self.read_dcm_as_array(dcm_path, self.target_size, color_mode=self.color_mode)\n","                            for dcm_path in self.x.iloc[indices_array]])\n","\n","        batch_y = np.array(self.y.iloc[indices_array].astype(np.uint8))  # astype because y was passed as str\n","        \n","        # transform images\n","        if self.image_data_generator is not None:\n","            for i, (x, y) in enumerate(zip(batch_x, batch_y)):\n","                transform_params = self.image_data_generator.get_random_transform(x.shape)\n","                batch_x[i] = self.image_data_generator.apply_transform(x, transform_params)\n","                # you can change y here as well, eg: in semantic segmentation you want to transform masks as well \n","                # using the same image_data_generator transformations.\n","\n","        return batch_x, batch_y\n","\n","    @staticmethod\n","    def read_dcm_as_array(dcm_path, target_size=(300, 300), color_mode='rgb'):\n","        image_array = pydicom.dcmread(dcm_path).pixel_array\n","        pixels = image_array - np.min(image_array)\n","        pixels = pixels / np.max(pixels)\n","        image_manual_norm = (pixels * 255).astype(np.uint8)\n","        image_array = cv2.resize(image_manual_norm, target_size, interpolation=cv2.INTER_NEAREST)  #this returns a 2d array\n","#         image_array = np.expand_dims(image_array, -1)\n","        if color_mode == 'rgb':\n","            image_array = np.dstack((image_array, np.zeros_like(image_array), np.zeros_like(image_array)))\n","        return image_array"]},{"cell_type":"code","execution_count":137,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T19:32:09.254121Z","iopub.status.busy":"2021-12-20T19:32:09.253355Z","iopub.status.idle":"2021-12-20T19:32:09.265416Z","shell.execute_reply":"2021-12-20T19:32:09.264592Z","shell.execute_reply.started":"2021-12-20T19:32:09.254084Z"},"trusted":true},"outputs":[],"source":["SEED = 369\n","BATCH_SIZE = 128\n","CLASS_MODE = 'binary'\n","COLOR_MODE = 'rgb'\n","TARGET_SIZE = (300, 300)"]},{"cell_type":"markdown","metadata":{},"source":["## Generate data by  using appropriate data augmentation properties"]},{"cell_type":"code","execution_count":138,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T19:32:09.267688Z","iopub.status.busy":"2021-12-20T19:32:09.267278Z","iopub.status.idle":"2021-12-20T19:32:09.280804Z","shell.execute_reply":"2021-12-20T19:32:09.279978Z","shell.execute_reply.started":"2021-12-20T19:32:09.267652Z"},"trusted":true},"outputs":[],"source":["def get_data_generators(train_df,val_df, test_df):\n","    train_augmentation_parameters = dict(\n","        rescale=1.0/255,\n","        zoom_range=0.2,\n","        rotation_range=0.2,\n","        fill_mode='nearest',\n","        height_shift_range= 0.1,\n","        width_shift_range=0.1,\n","        horizontal_flip=True,\n","        brightness_range = [0.8, 1.2]\n","    )\n","    \n","    val_augmentation_parameters = dict(\n","        rescale=1.0/255.0\n","    )\n","\n","    test_augmentation_parameters = dict(\n","        rescale=1.0/255.0\n","    )\n","\n","    train_consts = {\n","        'seed': SEED,\n","        'batch_size': BATCH_SIZE,\n","        'class_mode': CLASS_MODE,\n","        'color_mode': COLOR_MODE,\n","        'target_size': TARGET_SIZE,  \n","    }\n","    \n","    val_consts = {\n","    'batch_size': BATCH_SIZE,\n","    'class_mode': CLASS_MODE,\n","    'color_mode': COLOR_MODE,\n","    'target_size': TARGET_SIZE,\n","    'shuffle': False\n","    }\n","\n","    test_consts = {\n","        'batch_size': BATCH_SIZE,\n","        'class_mode': CLASS_MODE,\n","        'color_mode': COLOR_MODE,\n","        'target_size': TARGET_SIZE,\n","        'shuffle': False\n","    }\n","\n","    train_augmenter = ImageDataGenerator(**train_augmentation_parameters)\n","    val_augmenter = ImageDataGenerator(**val_augmentation_parameters)\n","    test_augmenter = ImageDataGenerator(**test_augmentation_parameters)\n","\n","    train_generator = DCMDataFrameIterator(dataframe=train_df,\n","                                 x_col='file_paths',\n","                                 y_col='labels',\n","                                 image_data_generator=train_augmenter,\n","                                 **train_consts)\n","    \n","    val_generator = DCMDataFrameIterator(dataframe=val_df,\n","                                 x_col='file_paths',\n","                                 y_col='labels',\n","                                 image_data_generator=None,\n","                                 **val_consts)\n","    \n","    test_generator = DCMDataFrameIterator(dataframe=test_df,\n","                                 x_col='file_paths',\n","                                 y_col='labels',\n","                                 image_data_generator=None,\n","                                 **test_consts)\n","    return train_generator, val_generator, test_generator"]},{"cell_type":"markdown","metadata":{},"source":["# Build Model\n","Replace the following lines in the code below:\n","1. model = VGG16(include_top=False,weights=weights_path)\n","2. model = Model(model.inputs, outputs, name=\"VGG16\")\n","By default this is set to VGG16 but you can replace this with any model that you would like to run"]},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T19:32:09.282621Z","iopub.status.busy":"2021-12-20T19:32:09.282255Z","iopub.status.idle":"2021-12-20T19:32:09.295072Z","shell.execute_reply":"2021-12-20T19:32:09.294179Z","shell.execute_reply.started":"2021-12-20T19:32:09.282574Z"},"trusted":true},"outputs":[],"source":["def build_model(weights_path):\n","    \n","    #Replace this with the model you would like to run\n","    model = VGG16(include_top=False,weights=weights_path)\n","    #model = tf.keras.applications.ResNet50(include_top=False,weights=weights_path)\n","    #model = EfficientNetB3(include_top=False, weights=weights_path)\n","    \n","    model.trainable = False\n","    \n","    x = GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n","    x = BatchNormalization()(x)\n","\n","    top_dropout_rate = 0.4\n","    x = Dropout(top_dropout_rate)(x)\n","    x = Dense(32, activation=\"relu\")(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(top_dropout_rate)(x)\n","    outputs = Dense(1, activation=\"sigmoid\", name=\"pred\")(x)\n","    \n","\n","     #Replace this with the model you would like to run\n","    model = Model(model.inputs, outputs, name=\"VGG16\")\n","    #model = Model(model.inputs, outputs, name=\"ResNet50\")\n","    #model = Model(model.inputs, outputs, name=\"EfficientNet\")\n","    \n","\n","    optimizer =  tf.keras.optimizers.Adam(learning_rate=1e-3)\n","    \n","    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\",AUC()])\n","    print(model.summary())\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["# Train Model\n","Replace the following lines in the code below:\n","#Replace this with appropriate path to the weights of the model you would like to run\n","1. model = build_model(\"../input/vgg16-weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")"]},{"cell_type":"code","execution_count":140,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T19:32:09.296663Z","iopub.status.busy":"2021-12-20T19:32:09.296253Z","iopub.status.idle":"2021-12-20T19:32:09.307946Z","shell.execute_reply":"2021-12-20T19:32:09.307112Z","shell.execute_reply.started":"2021-12-20T19:32:09.296626Z"},"trusted":true},"outputs":[],"source":["checkpoint_filepath = 'best_model.h5'\n","\n","def train_model(model_name, train_generator, val_generator, epochs):\n","    \n","    print('training', model_name)\n","    \n","    #Replace this with appropriate path to the weights of the model you would like to run\n","    model = build_model(\"../input/vgg16-weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n","    #model = build_model(\"../input/vgg19weights/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n","    #model = build_model(\"../input/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n","\n","    #callbacks\n","    \n","    checkpoint_cb=ModelCheckpoint(\n","        filepath=checkpoint_filepath,\n","        save_weights_only=False,\n","        monitor='val_loss',\n","        mode='min',\n","        save_best_only=True,\n","        save_freq='epoch',\n","        verbose=1)\n","    \n","    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                                  patience=5,\n","                                                  mode='min',\n","                                                  verbose=1,\n","                                                  restore_best_weights=True)\n","\n","    reduce_lr_cb=ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n","                                   patience=2, min_lr=0.00001,\n","                                  verbose=1)\n","\n","    history = model.fit(\n","                        train_generator,\n","                        steps_per_epoch=len(train_generator),\n","                        validation_data=val_generator,\n","                        validation_steps=len(val_generator),\n","                        epochs=epochs,\n","                        workers=2,\n","                        callbacks=[checkpoint_cb, reduce_lr_cb, early_stopping_cb]\n","                        )\n","    print(history.history.keys())\n","\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["## The code below computes accuracy at MRI Level. \n","test loss, test acc, test AUC are the test results for a particular scan type"]},{"cell_type":"code","execution_count":141,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T19:32:09.310488Z","iopub.status.busy":"2021-12-20T19:32:09.309584Z","iopub.status.idle":"2021-12-20T21:45:24.877018Z","shell.execute_reply":"2021-12-20T21:45:24.875498Z","shell.execute_reply.started":"2021-12-20T19:32:09.310440Z"},"trusted":true},"outputs":[],"source":["%%time\n","# train a model for each of the mri types and then ensemble predictions\n","all_test_preds = []\n","all_test_preds_with_ids = []\n","\n","for mt in ['flair', 't1w', 't1wce', 't2w']:\n","    train_df, val_df = get_train_val_dataframe(mt)\n","    test_df = get_test_dataframe(mt)\n","    train_g, val_g, test_g = get_data_generators(train_df, val_df, test_df)\n","    best_model =  train_model(mt, train_g, val_g, epochs=20)\n","    results = best_model.evaluate(test_g, steps=len(test_g))\n","    #test results for a scan types\n","    print(f\"test loss, test acc, test AUC: {results}\")\n","    test_pred = best_model.predict(test_g, steps=len(test_g))\n","    test_df['pred_y'] = test_pred\n","    # aggregate the predictions on all image for each person -- needed to calculate accuracy at patient level\n","    mean_pred = test_pred.mean()\n","    test_pred_agg = test_df.groupby('patient_ids').apply(\n","        lambda x: x['pred_y'].max()\n","        if (x['pred_y'].max() - mean_pred) > (mean_pred - x['pred_y'].min()) \n","        else x['pred_y'].min())\n","    all_test_preds.append(test_pred_agg.values)\n","    all_test_preds_with_ids.append(test_pred_agg)"]},{"cell_type":"markdown","metadata":{},"source":["# Get Accuracy at Patient Level"]},{"cell_type":"code","execution_count":142,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T21:45:24.882598Z","iopub.status.busy":"2021-12-20T21:45:24.881230Z","iopub.status.idle":"2021-12-20T21:45:24.922662Z","shell.execute_reply":"2021-12-20T21:45:24.921798Z","shell.execute_reply.started":"2021-12-20T21:45:24.882564Z"},"trusted":true},"outputs":[],"source":["\n","all_test_preds = np.array(all_test_preds)\n","\n","grouped_df = test_df.groupby('patient_ids')\n","grouped_df = test_df.groupby('patient_ids').apply(lambda x:  pd.to_numeric(x['labels'],errors='coerce').mean())\n","a = np.array(grouped_df)\n","results = all_test_preds.mean(0)\n","\n","#labels = pd.to_numeric(test_df['labels'],errors='coerce')\n","\n","count = 0\n","for idx in range(len(a)):\n","    val = results[idx]\n","    if (val >= 0.5 and a[idx] >= 0.5):\n","        count = count + 1\n","    if (val <= 0.5 and a[idx] < 0.5):\n","        count = count + 1\n","accuracy = count/len(results)\n","print('Accuracy at Patient Level:')\n","print(accuracy)"]},{"cell_type":"code","execution_count":143,"metadata":{"execution":{"iopub.execute_input":"2021-12-20T21:45:24.926014Z","iopub.status.busy":"2021-12-20T21:45:24.925421Z","iopub.status.idle":"2021-12-20T21:45:25.188364Z","shell.execute_reply":"2021-12-20T21:45:25.187672Z","shell.execute_reply.started":"2021-12-20T21:45:24.925973Z"},"trusted":true},"outputs":[],"source":["plt.hist(all_test_preds.mean(0))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
