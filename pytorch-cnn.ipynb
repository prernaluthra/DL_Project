{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Imports\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport sklearn\nimport torchvision\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport seaborn as sns\nimport glob\nfrom pathlib import Path\nimport cv2\ntorch.manual_seed(1)\nnp.random.seed(1)\nimport re\nimport pydicom\nimport math\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:27.749042Z","iopub.execute_input":"2021-12-20T22:24:27.749687Z","iopub.status.idle":"2021-12-20T22:24:34.632402Z","shell.execute_reply.started":"2021-12-20T22:24:27.749561Z","shell.execute_reply":"2021-12-20T22:24:34.631668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dimensions\nIMAGE_SIZE = 256\nNUM_IMAGES = 64\nBATCH_SIZE= 4","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.633877Z","iopub.execute_input":"2021-12-20T22:24:34.634131Z","iopub.status.idle":"2021-12-20T22:24:34.639822Z","shell.execute_reply.started":"2021-12-20T22:24:34.6341Z","shell.execute_reply":"2021-12-20T22:24:34.638068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Loading and Visualizations**","metadata":{}},{"cell_type":"code","source":"def loading_image(path, img_size=IMAGE_SIZE):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    data = apply_voi_lut(dicom.pixel_array, dicom)\n    data = cv2.resize(data, (img_size, img_size))\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.641321Z","iopub.execute_input":"2021-12-20T22:24:34.6416Z","iopub.status.idle":"2021-12-20T22:24:34.648869Z","shell.execute_reply.started":"2021-12-20T22:24:34.641564Z","shell.execute_reply":"2021-12-20T22:24:34.648168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_3d_image(idx, mri_type, num_imgs=NUM_IMAGES, split='train'):\n    files = sorted(glob.glob(f\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/{split}/{idx}/{mri_type}/*.dcm\"), \n                   key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n    middle = int(len(files) / 2)\n    half_num_imgs = int(num_imgs / 2)\n    start = max(0, middle - half_num_imgs)\n    end = min(len(files) + 1, middle + half_num_imgs)\n\n    arrays = [loading_image(f) for f in files[start:end]]\n    img3d = np.stack(arrays, axis=2)\n    \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((IMAGE_SIZE, IMAGE_SIZE, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis=-1)\n        \n    if np.min(img3d) < np.max(img3d):\n        img3d = img3d - np.min(img3d)\n        img3d = img3d / np.max(img3d)\n\n    return img3d\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.651223Z","iopub.execute_input":"2021-12-20T22:24:34.651484Z","iopub.status.idle":"2021-12-20T22:24:34.66167Z","shell.execute_reply.started":"2021-12-20T22:24:34.651451Z","shell.execute_reply":"2021-12-20T22:24:34.660875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.663167Z","iopub.execute_input":"2021-12-20T22:24:34.663693Z","iopub.status.idle":"2021-12-20T22:24:34.682247Z","shell.execute_reply.started":"2021-12-20T22:24:34.66366Z","shell.execute_reply":"2021-12-20T22:24:34.681664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.68373Z","iopub.execute_input":"2021-12-20T22:24:34.683915Z","iopub.status.idle":"2021-12-20T22:24:34.706052Z","shell.execute_reply.started":"2021-12-20T22:24:34.683894Z","shell.execute_reply":"2021-12-20T22:24:34.70545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_files = sorted(os.listdir('../input/rsna-miccai-png/train'))","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.707116Z","iopub.execute_input":"2021-12-20T22:24:34.707367Z","iopub.status.idle":"2021-12-20T22:24:34.744867Z","shell.execute_reply.started":"2021-12-20T22:24:34.707337Z","shell.execute_reply":"2021-12-20T22:24:34.744167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_files)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.746393Z","iopub.execute_input":"2021-12-20T22:24:34.746579Z","iopub.status.idle":"2021-12-20T22:24:34.754545Z","shell.execute_reply.started":"2021-12-20T22:24:34.746558Z","shell.execute_reply":"2021-12-20T22:24:34.753759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_files = pd.Series(train_files, name='train_files')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.756338Z","iopub.execute_input":"2021-12-20T22:24:34.756692Z","iopub.status.idle":"2021-12-20T22:24:34.761827Z","shell.execute_reply.started":"2021-12-20T22:24:34.756654Z","shell.execute_reply":"2021-12-20T22:24:34.761005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = pd.concat([train_labels, train_files], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.766466Z","iopub.execute_input":"2021-12-20T22:24:34.766693Z","iopub.status.idle":"2021-12-20T22:24:34.773645Z","shell.execute_reply.started":"2021-12-20T22:24:34.766668Z","shell.execute_reply":"2021-12-20T22:24:34.772951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.776404Z","iopub.execute_input":"2021-12-20T22:24:34.776594Z","iopub.status.idle":"2021-12-20T22:24:34.788401Z","shell.execute_reply.started":"2021-12-20T22:24:34.776573Z","shell.execute_reply":"2021-12-20T22:24:34.78761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = train_labels[train_labels['BraTS21ID'] != 109]","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.789687Z","iopub.execute_input":"2021-12-20T22:24:34.790021Z","iopub.status.idle":"2021-12-20T22:24:34.81Z","shell.execute_reply.started":"2021-12-20T22:24:34.789987Z","shell.execute_reply":"2021-12-20T22:24:34.809325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = train_labels[train_labels['BraTS21ID'] != 709]","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.811206Z","iopub.execute_input":"2021-12-20T22:24:34.811461Z","iopub.status.idle":"2021-12-20T22:24:34.815985Z","shell.execute_reply.started":"2021-12-20T22:24:34.81143Z","shell.execute_reply":"2021-12-20T22:24:34.815253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"109 and 709 don't have flair images so for this dataset. ","metadata":{}},{"cell_type":"code","source":"train_labels['MGMT_value'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.817664Z","iopub.execute_input":"2021-12-20T22:24:34.818229Z","iopub.status.idle":"2021-12-20T22:24:34.827783Z","shell.execute_reply.started":"2021-12-20T22:24:34.818195Z","shell.execute_reply":"2021-12-20T22:24:34.826882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fairly balanced train set.","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv')\ntest_ids = []\nfor f in test_data.itertuples():\n    test_ids.append(f[1])","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.829505Z","iopub.execute_input":"2021-12-20T22:24:34.829819Z","iopub.status.idle":"2021-12-20T22:24:34.848325Z","shell.execute_reply.started":"2021-12-20T22:24:34.829784Z","shell.execute_reply":"2021-12-20T22:24:34.847697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = load_3d_image(\"00000\", \"FLAIR\")\nprint(a.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:34.849758Z","iopub.execute_input":"2021-12-20T22:24:34.850021Z","iopub.status.idle":"2021-12-20T22:24:35.876517Z","shell.execute_reply.started":"2021-12-20T22:24:34.849989Z","shell.execute_reply":"2021-12-20T22:24:35.875699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(load_3d_image(\"00122\", \"FLAIR\")[:, :, 2], cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:35.878012Z","iopub.execute_input":"2021-12-20T22:24:35.878419Z","iopub.status.idle":"2021-12-20T22:24:36.391374Z","shell.execute_reply.started":"2021-12-20T22:24:35.878376Z","shell.execute_reply":"2021-12-20T22:24:36.390733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Dataset and DataLoader**","metadata":{}},{"cell_type":"code","source":"class TumorDataset(torch.utils.data.Dataset):\n    def __init__(self, df=train_labels, transform=transforms.Compose([transforms.ToTensor()]), mri_type=\"T1wCE\", train=True):\n        self.df = df\n        self.transform = transform\n        self.type = mri_type\n        self.train = train\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n            if self.train == True:\n                patient_id = self.df.iloc[idx, 2]\n                \n                image = load_3d_image(str(patient_id), self.type)\n                image = self.transform(image)\n                image = image[None, :, :, :]\n                label = self.df.iloc[idx, 1]\n                label = torch.tensor(label)\n                \n                return image, label\n            \n            else:\n                patient_id = self.df[idx]\n                patient_id = str(patient_id)\n                for i in range(5 - len(patient_id)):\n                    patient_id = '0' + patient_id\n                \n                \n                image = load_3d_image(patient_id, self.type, split='test')\n                image = self.transform(image)\n                image = image[None, :, :, :]\n                \n                return image, idx","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:36.392465Z","iopub.execute_input":"2021-12-20T22:24:36.393309Z","iopub.status.idle":"2021-12-20T22:24:36.404071Z","shell.execute_reply.started":"2021-12-20T22:24:36.39327Z","shell.execute_reply":"2021-12-20T22:24:36.403273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TumorDataset()\ntest_dataset = TumorDataset(df=test_ids, train=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:36.40569Z","iopub.execute_input":"2021-12-20T22:24:36.406278Z","iopub.status.idle":"2021-12-20T22:24:36.413147Z","shell.execute_reply.started":"2021-12-20T22:24:36.406243Z","shell.execute_reply":"2021-12-20T22:24:36.412489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=4)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:36.414398Z","iopub.execute_input":"2021-12-20T22:24:36.414678Z","iopub.status.idle":"2021-12-20T22:24:36.421399Z","shell.execute_reply.started":"2021-12-20T22:24:36.414644Z","shell.execute_reply":"2021-12-20T22:24:36.420801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:36.422927Z","iopub.execute_input":"2021-12-20T22:24:36.423318Z","iopub.status.idle":"2021-12-20T22:24:36.483889Z","shell.execute_reply.started":"2021-12-20T22:24:36.42315Z","shell.execute_reply":"2021-12-20T22:24:36.482951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Simple Model Architecture**","metadata":{}},{"cell_type":"code","source":"class ThreeDNetwork(nn.Module):\n    \n    def conv_layer(self, in_channels, out_channels, kernel_size, stride=2):\n        conv_layer = nn.Sequential(\n            nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride),\n            nn.LeakyReLU(),\n            nn.MaxPool3d((2, 2, 2)),\n            nn.BatchNorm3d(out_channels))\n        return conv_layer\n    \n    def __init__(self, batch_size=BATCH_SIZE):\n        super(ThreeDNetwork, self).__init__()\n        self.batch_size = batch_size\n        self.block1 = nn.Sequential(\n            self.conv_layer(1, 64, 3, 2),\n            self.conv_layer(64, 128, 3, 2))\n        \n        self.fc = nn.Sequential(\n            nn.Linear(86400, 1024),\n            nn.LeakyReLU(),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.2),\n            nn.Linear(1024, 1))\n        \n    def forward(self, x):\n        x = self.block1(x)\n        x = x.view(-1, 86400)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:36.486935Z","iopub.execute_input":"2021-12-20T22:24:36.487166Z","iopub.status.idle":"2021-12-20T22:24:36.497072Z","shell.execute_reply.started":"2021-12-20T22:24:36.487143Z","shell.execute_reply":"2021-12-20T22:24:36.496202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ThreeDNetwork()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:24:36.498416Z","iopub.execute_input":"2021-12-20T22:24:36.49902Z","iopub.status.idle":"2021-12-20T22:24:37.177382Z","shell.execute_reply.started":"2021-12-20T22:24:36.498985Z","shell.execute_reply":"2021-12-20T22:24:37.176575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:25:32.693438Z","iopub.execute_input":"2021-12-20T22:25:32.693838Z","iopub.status.idle":"2021-12-20T22:25:32.699292Z","shell.execute_reply.started":"2021-12-20T22:25:32.693801Z","shell.execute_reply":"2021-12-20T22:25:32.698082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ntrain_criterion = nn.BCELoss()\nlr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=4, cooldown=2, verbose=True)\n\nmodel = model.to(device)\ntrain_criterion = train_criterion.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:25:32.701262Z","iopub.execute_input":"2021-12-20T22:25:32.701572Z","iopub.status.idle":"2021-12-20T22:25:38.284872Z","shell.execute_reply.started":"2021-12-20T22:25:32.701538Z","shell.execute_reply":"2021-12-20T22:25:38.284131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 30\n\ntotal_train_loss = []\nbest_train_loss = np.Inf\n\nfor epoch in range(epochs): \n    print('Epoch: ', epoch + 1)\n    train_loss = []\n    train_correct = 0\n    train_total = 0\n    for image, target in train_loader:\n        optimizer.zero_grad()\n        new_target = []\n        for element in target:\n            new_target.append([element])\n        new_target = torch.tensor(new_target, dtype=torch.float)\n        image = image.float()\n        image, new_target = image.to(device), new_target.to(device)\n        output = model(image)\n        output = nn.Sigmoid()(output)\n        loss = train_criterion(output, new_target)\n        loss.backward()\n        optimizer.step()\n        train_loss.append(loss.item())\n            \n    epoch_train_loss = np.mean(train_loss)\n    print(f'Epoch {epoch + 1}, train loss: {epoch_train_loss:.4f}')\n    \n    if epoch_train_loss < best_train_loss:\n        torch.save(model.state_dict(), 'tumor.pth')\n        print('Model improved. Saving model.')\n        best_train_loss = epoch_train_loss\n        \n    lr_scheduler.step(epoch_train_loss)\n    total_train_loss.append(epoch_train_loss)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T22:25:38.286022Z","iopub.execute_input":"2021-12-20T22:25:38.28776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(total_train_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rounding(num):\n    return math.floor(num + 0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('tumor.pth'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = 0\ntotal = 0\n\nwith torch.no_grad():\n    model.eval()\n    for image, target in train_loader:\n        new_target = []\n        for element in target:\n            new_target.append([element])\n        new_target = torch.tensor(new_target, dtype=torch.int)\n        image = image.float()\n        image, new_target = image.to(device), new_target.to(device)\n        output = model(image)\n        output = nn.Sigmoid()(output)\n        predicted = []\n        for element in output:\n            predicted.append([rounding(element)])\n        predicted = torch.tensor(predicted, dtype=torch.int)\n        predicted = predicted.to(device)\n        total += BATCH_SIZE\n\n        num_correct = 0\n        for i, element in enumerate(predicted):\n            if element == new_target[i]:\n                num_correct += 1\n                \n        correct += num_correct\n\nprint('Train Accuracy: %d %%' % (100 * correct / total))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Inference**","metadata":{}},{"cell_type":"code","source":"id_series = []\nmgmt_series = []\n\nwith torch.no_grad():\n    for image, idx in test_loader:\n        image = image.float()\n        image = image.to(device)\n        output = model(image)\n        output = nn.Sigmoid()(output)\n        for element in output:\n            for el in element.cpu().numpy():\n                mgmt_series.append(float(math.trunc(el * 10000) / 10000.0))\n        idx = idx.tolist()\n        for element in idx:\n            id_series.append(element)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brats_id_series = []\nfor idx in id_series:\n    brats_id_series.append(int(test_ids[idx]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brats_id_series = pd.Series(brats_id_series, name='BraTS21ID')\nmgmt_series = pd.Series(mgmt_series, name='MGMT_value')\ntest_preds = pd.concat([brats_id_series, mgmt_series], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}